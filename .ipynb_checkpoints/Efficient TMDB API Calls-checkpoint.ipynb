{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac2d81a-3046-48f5-a549-d93c5b670ba0",
   "metadata": {},
   "source": [
    "**Efficient TMDB API Calls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d36b2-b869-42ad-90ce-d86617752e4c",
   "metadata": {},
   "source": [
    "**Planning**\n",
    "\n",
    "Before jumping into the code, it is important to outline in plain language what you are trying to do. Before you can ask the computer to do it, you have to really understand what you are asking. This week has introduced some new code that you may still be getting used to, so this lesson will help walk you through the task. We will go through the individual pieces of code, but for the project, you will need to put it all together, in a logical order, with correct formatting! There will be an OUTER and INNER loop: a loop within a loop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fcd947-5fdb-45da-bfea-51d892c83298",
   "metadata": {},
   "source": [
    "**Our goal will be to**\n",
    "\n",
    "- Determine where to save our results and in what file format.\n",
    "- Decide what subset of movies to retrieve (based on Years).\n",
    "- Develop code to make API calls based on our existing IMDB IDs with the INNER Loop\n",
    "- Organize output by year into separate .json files using an OUTER LOOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2603e-d95b-4488-9775-a5844da88e51",
   "metadata": {},
   "source": [
    "**BEFORE the Loops**\n",
    "\n",
    "- Designate a folder to save your information\n",
    "- Define the years you wish to retrieve\n",
    "- Define any custom functions you will use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69fce8-f70d-4e9c-97fa-400445ae5f47",
   "metadata": {},
   "source": [
    "**Create an OUTER loop for each year with a progress bar using tqdm_notebook**\n",
    "\n",
    "- Define a JSON_FILE filename to save the results in progress.\n",
    "   - Check if the file exists.\n",
    "     - if no:\n",
    "        - Create the empty JSON file with with open that just contains the key \"imdb_id\"\n",
    "     - if yes:\n",
    "        - Do nothing.\n",
    "- Define/filter the movie IDs you want to retrieve (that belongs to the year being retrieved)\n",
    "- Check for and remove any previously downloaded movie IDs to prevent duplicate API calls.\n",
    "   - Load in any existing/previous results with pd.read_json\n",
    "      - Check to see if any of the movie_ids to get are already in the JSON file.\n",
    "      - Filter out only movies that are missing from the JSON file to use in the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09a2f0-5035-484e-989b-3213f5e29150",
   "metadata": {},
   "source": [
    "**Create an INNER loop to make API calls for each id in the YEAR specified in the outer loop. For each id:**\n",
    "\n",
    "- Load up results thus far from the JSON file as a list.\n",
    "- Extract the current ID from API and extract the dictionary of results\n",
    "- Append the new results to the list from the JSON file\n",
    "- Save the updated JSON file back to the disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2411d-4b3d-43d9-94d0-36d8d98de5a0",
   "metadata": {},
   "source": [
    "**After the inner loop,** save the final results for that year as a csv.gz file with the year in the filename.\n",
    "\n",
    " - Then, the outer loop repeats for the remaining years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a74d99-65f5-4fcf-8f52-109e4626fe80",
   "metadata": {},
   "source": [
    "**BEFORE THE LOOPS**\n",
    "\n",
    "**Designate a folder**\n",
    "\n",
    "You will save API call data in the data folder you created for project Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a813aa4-210e-4fef-80dc-a11fe2619246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_results_NY_pizza.csv.gz',\n",
       " 'final_results_NY_Steak.csv.gz',\n",
       " 'results_in_progress_NY_pizza.json',\n",
       " 'results_in_progress_NY_Steak.json',\n",
       " 'title_basics.csv.gz',\n",
       " 'tmdb_data_2000.csv.gz',\n",
       " 'tmdb_data_2001.csv.gz']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, time,json\n",
    "import tmdbsimple as tmdb \n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045af211-a435-48a5-9121-53b806a8a9d8",
   "metadata": {},
   "source": [
    "**Define Your Functions**\n",
    "\n",
    "You should ultimately put any custom functions at the top of your notebook. You can first write them where you first use them in your project, but once you have the functions completed and tested, you should move their definitions to the top of your notebook after you import your packages.\n",
    "\n",
    "You will need your function to get the movie rating from the prior lesson, as well as the new function below: write_json. This is a modified version of a function from **https://www.geeksforgeeks.org/append-to-json-file-using-python/**. Notice that the original source link is included in the function's docstring to give proper credit to the original authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3caada-c798-4f5a-9048-aeac3f826373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaaac5f-8eff-4908-b585-a1ab106cbd79",
   "metadata": {},
   "source": [
    "**Load in the Title Basics data**\n",
    "\n",
    "You need to read in the filtered dataframe you created based on the specification of Project 3 Part 1.\n",
    "\n",
    "You will be filtering out the movies for each year inside the loop, so we will need this loaded and ready to be filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b30a53-2141-4ffb-a114-251a5b26befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataframe from project part 1 as basics:\n",
    "basics = pd.read_csv('/Users/tspiet/Documents/GitHub/Data_Enrichment/Data-Enrichment/Data/title_basics.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36666020-0dcc-4989-b249-af598dc60e33",
   "metadata": {},
   "source": [
    "**Create Required Lists for the Loop**\n",
    "    \n",
    "Define a list of the Years to Extract from the API\n",
    "\n",
    "We have data from 2000 - 2020 available. If we just want results for the first two years, we will create a YEARS_TO_GET list that only contains those 2 years (for now). This will control our outer loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2a8989-ddac-4f97-bb0b-692f236023a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_GET = [2000,2001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d0e41-038a-4c2a-a609-ccaa5c6edc62",
   "metadata": {},
   "source": [
    "**Define an errors list**\n",
    "\n",
    "We will want to be able to save the ids and error messages for any movie that causes an error. To do so, we will want to create an empty errors list before our loops that we can append to later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ada0df-0f60-493e-9a0b-72cdcb287c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cec27-b555-40ac-9168-6b0b55f9ac93",
   "metadata": {},
   "source": [
    "**----Start OUTER Loop----**\n",
    "\n",
    "**Ultimately we will be creating a loop, but let's explore each piece of the code:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bdcb1-2354-49ca-88ec-bdb4e71f995c",
   "metadata": {},
   "source": [
    "**Set up Progress Bar**\n",
    "\n",
    "We want to keep track of our progress and ensure our calls are working. The progress bar works within the for statement of the for loop. Note that this will iterate through each year that is defined in the YEARS_TO_GET variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e49d3118-9713-43e1-8867-80efc13fc013",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (881592417.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\u001b[0m\n\u001b[1;37m                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Start of OUTER loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b95025-f04c-4526-b824-77581a8a6dba",
   "metadata": {},
   "source": [
    "**Select a JSON_FILE filename to save the results in progress.**\n",
    "\n",
    " - Check if the file exists.\n",
    "   - if no:\n",
    "       - Create the empty JSON file with with open that just contains the key \"imdb_id\"\n",
    "   - if yes:\n",
    "       - Do nothing.\n",
    "First, define the file path and names: We are going to have multiple files since we are creating a separate file for each year. The code below will identify the folder in the FOLDER we just defined above and will name the file based on the current year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873333b6-cfe4-461a-9b6f-bbce71ed70a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YEAR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Defining the JSON file to store results for year\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m JSON_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtmdb_api_results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'YEAR' is not defined"
     ]
    }
   ],
   "source": [
    "#Defining the JSON file to store results for year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f9591-48ef-48f9-9726-ad9a5b271e7b",
   "metadata": {},
   "source": [
    "Check if that file already exists or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5af01-dabf-4dce-965e-964bb009837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205991bf-e274-49ec-b2bb-1bbe030ddabc",
   "metadata": {},
   "source": [
    "The code below will create the file and save an empty dictionary with just imdb_id. We will be appending to this empty dictionary throughout our calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4b8d7-2a3f-42eb-8833-d4f6b0e3b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it does not exist: create it\n",
    "if file_exists == False:\n",
    "# save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94789291-c11a-437f-91f1-280ef3e46f18",
   "metadata": {},
   "source": [
    "**Define/filter the IDs to call**\n",
    "    \n",
    "We are going to break up our title_basics data by year, so we will define a new dataframe for each year. Notice that which YEAR will depend on what we define YEAR as. Leaving YEAR a variable allows the code to be easier to read and reproduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92d6ec-ece3-4d01-978a-c93a76ed0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving new year as the current df\n",
    "df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "# saving movie ids to list\n",
    "movie_ids = df['tconst'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b03954-aa38-40f5-807b-0f697ac412d7",
   "metadata": {},
   "source": [
    "**Check for and remove any previously downloaded Movie id's**\n",
    "\n",
    "You may remember from our lesson on efficient API calls that we are going to build in some safeguards when looping through multiple calls.\n",
    "\n",
    "- Load in any existing API results with pd.read_json\n",
    "- Check to see if any of the movie_ids to get are already in the JSON file.\n",
    "- Filter out only movies that are missing from the JSON file to use in the loop\n",
    "The code loads any existing information from the JSON file into a dataframe called the \"previous_df.\" This will start empty, but as you iterate through the loop, it will continue to have more and more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb115c-38ba-4a16-ad06-09ff7ba2f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432dded-d034-4427-9283-ef5c8dd5354e",
   "metadata": {},
   "source": [
    "Now we have defined the \"movie_ids_to_get\". It includes the ids from our dataframe in the year we are seeking, and it excludes any that we have already made calls for.\n",
    "\n",
    "We will use this list for our inner loop of API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737db54-c027-4605-a86f-17c0426908f0",
   "metadata": {},
   "source": [
    "**----Start INNER Loop----**\n",
    "\n",
    "Now that we have the filtered list of movie_ids_to_get for the current year, we will now create an inner loop to iterate through the movie_ids_to_get, and for each ID, we will: retrieve the movie info from the TMDB API, append the movie_info dictionary to our JSON_FILE, wait 20 ms to avoid overwhelming the API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f3742-df66-4f85-84d0-85965f2ea913",
   "metadata": {},
   "source": [
    "**Iterate through the list of Movie IDs and make the calls**\n",
    "\n",
    "The code below relies on the function you wrote in the previous lesson that made API calls and added the certification to the .info results. Here this function is named \"get_movie_with_rating\". Make sure you have the function from the earlier lesson in the code file before you plan to call on it! This loop also uses the function above (write_json) to extend/append the results to the .json file. **Make sure both functions are defined in your code file before you try to call them!**\n",
    "\n",
    "Since some movies exist in IMDB's title basics dataset (our DataFrame) that do not exist within the database for TMDB's API, we will get an error whenever we attempt to retrieve a movie id that TMDB does not have in its database.\n",
    "\n",
    "To get around this, we will use a try and except statement around our inner loop. We will TRY to run the inner loop to retrieve and save the data for the current movie_id, but if we get an error, we will save the movie_id and error message in our errors list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878cd702-88a9-49b6-923f-e4c8a603a508",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            # Retrieve then data for the movie id\n",
    "            temp = get_movie_with_rating(movie_id)  \n",
    "            # Append/extend results to existing file using a pre-made function\n",
    "            write_json(temp,JSON_FILE)\n",
    "            # Short 20 ms sleep to prevent overwhelming server\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b233dc6-100f-4cd6-b2a6-9433a0c32c32",
   "metadata": {},
   "source": [
    "**After the Inner Loop**\n",
    "\n",
    "Once the inner loop through the current movie_ids_to_get has finished, we will have all of our results for that year in our JSON_FILE. We now want to save them in a smaller file format.\n",
    "Save the year's results as csv.gz file\n",
    "\n",
    "Once all of the API calls for the current year are made, you should open your .json file with pd.read_json and convert each json file to a compressed csv (\".csv.gz\") to save space. This is done after the inner loop but within the outer loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce248dc5-de18-4dd7-b28c-b0c116c3a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b686ac-f6e8-44f7-bce1-beed15a88c2a",
   "metadata": {},
   "source": [
    "**After Your Inner & Outer Loop**\n",
    "\n",
    "Print a message reporting back the number of movie ids that caused an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32045323-9f59-4dfe-9e44-21175fe3b953",
   "metadata": {},
   "source": [
    "**Troubleshooting:**\n",
    "  \n",
    "If you get an error message when trying to run pd.read_json, try replacing pd.read_json with the \"read_and_fix_json\" helper function in this repository: **https://github.com/coding-dojo-data-science/data-enrichment-helper-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d3b61-8c1c-4ef9-8095-e738f502609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of previous_df=pd.read_json:\n",
    "previous_df = read_and_fix_json(JSON_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21e35b-8bb6-4c07-9dde-3182db06c803",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "This lesson exemplifies the importance of planning your complex coding tasks so that you are clear on what you are trying to do in plain language before translating to code. While this lesson shows examples of the different segments of code that you may want to use in the next phase of the project, remember it is still up to you to read and understand each step so that you can put together the final product! **You will need to be conscientious of the order of the information and the appropriate format (especially tabs).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf7bb2-3225-4846-89f7-468480276b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
